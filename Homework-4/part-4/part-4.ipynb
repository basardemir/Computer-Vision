{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"train_dir = '../input/blg453e-competition-2-2021/image-classification/imagenet_50/train'\ntest_dir = '../input/blg453e-competition-2-2021/image-classification/imagenet_50/test/imgs'\n\nmodel1 = torch.load('../input/blg453e-competition-2-2021/image-classification/model_1.pth').cuda()\nmodel2 = torch.load('../input/blg453e-competition-2-2021/image-classification/model_2.pth').cuda()\nmodel3 = torch.load('../input/blg453e-competition-2-2021/image-classification/model_3.pth').cuda()\nmodel4 = torch.load('../input/blg453e-competition-2-2021/image-classification/model_4.pth').cuda()\n\nmodel1.eval()\nmodel2.eval()\nmodel3.eval()\nmodel4.eval()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T19:31:07.116979Z","iopub.execute_input":"2022-02-03T19:31:07.117697Z","iopub.status.idle":"2022-02-03T19:31:18.822281Z","shell.execute_reply.started":"2022-02-03T19:31:07.117660Z","shell.execute_reply":"2022-02-03T19:31:18.821550Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport PIL\nfrom torchvision import transforms\nimport torch\nimport torchvision.models as models\nimport os, glob\nimport numpy as np\nfrom imgaug import augmenters as iaa\nfrom imgaug import parameters as iap\nimport imgaug as ia","metadata":{"execution":{"iopub.status.busy":"2022-02-03T19:11:04.546083Z","iopub.execute_input":"2022-02-03T19:11:04.546646Z","iopub.status.idle":"2022-02-03T19:11:04.551152Z","shell.execute_reply.started":"2022-02-03T19:11:04.546606Z","shell.execute_reply":"2022-02-03T19:11:04.550467Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"\nseq_complex = iaa.Sequential(\n    [\n        iaa.Fliplr(0.5),\n        iaa.Flipud(0.5),\n        iaa.Sometimes(0.5, iaa.Affine(\n            scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n            rotate=(-45, 45),\n            order=[0, 1],\n            cval=(0, 255),\n            mode=ia.ALL\n        )),\n        iaa.SomeOf((0, 3),\n            [\n                iaa.OneOf([\n                    iaa.GaussianBlur((0, 3.0)),\n                    iaa.AverageBlur(k=(2, 7)),\n                    iaa.MedianBlur(k=(3, 11)),\n                ]),\n                iaa.AdditiveGaussianNoise(\n                    loc=0, scale=(0.0, 0.05*255), per_channel=0.5\n                ),\n                iaa.LinearContrast((0.5, 2.0), per_channel=0.5),\n            ],\n            random_order=True\n        )\n    ],\n    random_order=True\n)\n\n\ndef obtain_features(model, img):\n\tpreprocess = transforms.Compose([\n\t\ttransforms.Resize(256),\n\t\ttransforms.CenterCrop(224),\n\t\ttransforms.ToTensor(),\n\t\ttransforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n\t])\n\tinput_tensor = preprocess(img).cuda()\n\tinput_batch = input_tensor.unsqueeze(0)\n\n\twith torch.no_grad():\n\t\toutput = model(input_batch)\n\n\treturn output\n\n\ndef prepare_train_from_folder(dir, model1, model2, model3, model4):\n\timg_count = len(glob.glob(dir +'/*/*.JPEG'))*2\n\ttrain_folders = sorted(os.listdir(dir))\n\ttrain = np.zeros((img_count, 7936))\n\ttrain_labels = np.zeros((img_count,))\n\tcounter = 0\n\tfor i in range(len(train_folders)):\n\t\tall_imgs = os.listdir(dir + '/' + train_folders[i])\n\t\tfor j in range(len(all_imgs)):\n\t\t\timg = Image.open(dir + '/' + train_folders[i] + '/' + all_imgs[j])\n\t\t\timg = img.convert('RGB')\n            \n\t\t\tfeatures = obtain_features(model1, img).cpu().numpy()\n\t\t\tfeatures2 = obtain_features(model2, img).cpu().numpy()\n\t\t\tfeatures3 = obtain_features(model3, img).cpu().numpy()\n\t\t\tfeatures4 = obtain_features(model4, img).cpu().numpy()\n\t\t\tfeatures = np.concatenate((features, features2), axis=None)\n\t\t\tfeatures = np.concatenate((features, features3), axis=None)\n\t\t\tfeatures = np.concatenate((features, features4), axis=None)\n            \n\t\t\ttrain[counter, :] = features\n\t\t\ttrain_labels[counter] = i\n\t\t\tcounter += 1\n            \n\t\t\taug = seq_complex(images=[np.asarray(img)])\n\t\t\taug_img = PIL.Image.fromarray(np.uint8(aug[0]))\n            \n\t\t\tfeatures = obtain_features(model1, aug_img).cpu().numpy()\n\t\t\tfeatures2 = obtain_features(model2, aug_img).cpu().numpy()\n\t\t\tfeatures3 = obtain_features(model3, aug_img).cpu().numpy()\n\t\t\tfeatures4 = obtain_features(model4, aug_img).cpu().numpy()\n\t\t\tfeatures = np.concatenate((features, features2), axis=None)\n\t\t\tfeatures = np.concatenate((features, features3), axis=None)\n\t\t\tfeatures = np.concatenate((features, features4), axis=None)\n            \n\t\t\ttrain[counter, :] = features\n\t\t\ttrain_labels[counter] = i            \n\t\t\tcounter += 1\n\t\t\tprint(train.shape)\n            \n\treturn train, train_labels","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-03T19:31:38.519109Z","iopub.execute_input":"2022-02-03T19:31:38.519589Z","iopub.status.idle":"2022-02-03T19:31:38.555865Z","shell.execute_reply.started":"2022-02-03T19:31:38.519548Z","shell.execute_reply":"2022-02-03T19:31:38.555036Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"train1, train_labels1 = prepare_train_from_folder(train_dir, model1, model2, model3, model4)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T19:11:34.882161Z","iopub.execute_input":"2022-02-03T19:11:34.882507Z","iopub.status.idle":"2022-02-03T19:11:49.883110Z","shell.execute_reply.started":"2022-02-03T19:11:34.882470Z","shell.execute_reply":"2022-02-03T19:11:49.881899Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"with open('train.npy', 'wb') as f:\n    np.save(f, train)\n    np.save(f, train_labels)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T17:09:41.879261Z","iopub.execute_input":"2022-02-03T17:09:41.879968Z","iopub.status.idle":"2022-02-03T17:10:15.933431Z","shell.execute_reply.started":"2022-02-03T17:09:41.879934Z","shell.execute_reply":"2022-02-03T17:10:15.932686Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def prepare_test_from_folder(dir, model1, model2, model3, model4):\n\timg_count = len(glob.glob(dir + '/*.JPEG'))\n\n\ttest_files = sorted(os.listdir(dir))\n\n\ttest = np.zeros((img_count, 7936))\n\ttest_names = []\n\n\tcounter = 0\n\n\tfor i in range(len(test_files)):\n\t\timg = Image.open(dir +  '/' + test_files[i])\n\t\timg = img.convert('RGB')\n\n\t\tfeatures = obtain_features(model1, img).cpu().numpy()\n\t\tfeatures2 = obtain_features(model2, img).cpu().numpy()\n\t\tfeatures3 = obtain_features(model3, img).cpu().numpy()\n\t\tfeatures4 = obtain_features(model4, img).cpu().numpy()\n\t\tfeatures = np.concatenate((features, features2), axis=None)\n\t\tfeatures = np.concatenate((features, features3), axis=None)\n\t\tfeatures = np.concatenate((features, features4), axis=None)\n\n\t\ttest[counter, :] = features\n\n\t\ttest_names.append(test_files[i])\n\t\tcounter+=1    \n\n\treturn test, test_names","metadata":{"execution":{"iopub.status.busy":"2022-02-03T19:31:27.564788Z","iopub.execute_input":"2022-02-03T19:31:27.565068Z","iopub.status.idle":"2022-02-03T19:31:27.575386Z","shell.execute_reply.started":"2022-02-03T19:31:27.565037Z","shell.execute_reply":"2022-02-03T19:31:27.574449Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"test, test_names = prepare_test_from_folder(test_dir, model1, model2, model3, model4)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T19:31:43.890147Z","iopub.execute_input":"2022-02-03T19:31:43.890942Z","iopub.status.idle":"2022-02-03T20:21:29.172890Z","shell.execute_reply.started":"2022-02-03T19:31:43.890891Z","shell.execute_reply":"2022-02-03T20:21:29.172034Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"with open('test.npy', 'wb') as f:\n    np.save(f, test)\n    np.save(f, test_names)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:21:54.428298Z","iopub.execute_input":"2022-02-03T20:21:54.429001Z","iopub.status.idle":"2022-02-03T20:22:13.162639Z","shell.execute_reply.started":"2022-02-03T20:21:54.428954Z","shell.execute_reply":"2022-02-03T20:22:13.161692Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"print(test)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:22:21.012633Z","iopub.execute_input":"2022-02-03T20:22:21.012966Z","iopub.status.idle":"2022-02-03T20:22:21.025167Z","shell.execute_reply.started":"2022-02-03T20:22:21.012928Z","shell.execute_reply":"2022-02-03T20:22:21.024503Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport PIL\nfrom torchvision import transforms\nimport torch\nimport torchvision.models as models\nimport os, glob\nimport numpy as np\nfrom imgaug import augmenters as iaa\nfrom imgaug import parameters as iap\nimport imgaug as ia","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:28:53.182987Z","iopub.execute_input":"2022-02-03T20:28:53.183291Z","iopub.status.idle":"2022-02-03T20:28:53.189588Z","shell.execute_reply.started":"2022-02-03T20:28:53.183239Z","shell.execute_reply":"2022-02-03T20:28:53.188540Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"with open('train.npy', 'rb') as f:\n    train = np.load(f)\n    train_labels = np.load(f)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:29:45.157585Z","iopub.execute_input":"2022-02-03T20:29:45.158004Z","iopub.status.idle":"2022-02-03T20:29:57.742838Z","shell.execute_reply.started":"2022-02-03T20:29:45.157965Z","shell.execute_reply":"2022-02-03T20:29:57.739528Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_selection import VarianceThreshold\n\nprint(train.shape)\nselector = VarianceThreshold(0.3)\ntrain = selector.fit_transform(train)\n\nprint(train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T19:16:30.085264Z","iopub.execute_input":"2022-02-03T19:16:30.085526Z","iopub.status.idle":"2022-02-03T19:16:44.647386Z","shell.execute_reply.started":"2022-02-03T19:16:30.085490Z","shell.execute_reply":"2022-02-03T19:16:44.646567Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:27:43.364860Z","iopub.execute_input":"2022-02-03T20:27:43.365548Z","iopub.status.idle":"2022-02-03T20:27:43.373880Z","shell.execute_reply.started":"2022-02-03T20:27:43.365507Z","shell.execute_reply":"2022-02-03T20:27:43.373051Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components=2000, copy=False)\ntrain = pca.fit_transform(train)\nprint(train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T19:16:44.648606Z","iopub.execute_input":"2022-02-03T19:16:44.650387Z","iopub.status.idle":"2022-02-03T19:22:24.950744Z","shell.execute_reply.started":"2022-02-03T19:16:44.650342Z","shell.execute_reply":"2022-02-03T19:22:24.949882Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"with open('test.npy', 'rb') as f:\n    test = np.load(f)\n    test_labels = np.load(f)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:33:08.584176Z","iopub.execute_input":"2022-02-03T20:33:08.585360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = selector.transform(test)\ntest = pca.transform(test)\nprint(test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:22:37.127366Z","iopub.execute_input":"2022-02-03T20:22:37.127865Z","iopub.status.idle":"2022-02-03T20:23:18.666800Z","shell.execute_reply.started":"2022-02-03T20:22:37.127826Z","shell.execute_reply":"2022-02-03T20:23:18.665898Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"import cudf, cuml\nfrom cuml.neighbors import KNeighborsClassifier as cuKNeighbors\n\nknn = cuKNeighbors(n_neighbors=120)\nknn.fit(train,np.asarray(train_labels))","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:32:25.427575Z","iopub.execute_input":"2022-02-03T20:32:25.428480Z","iopub.status.idle":"2022-02-03T20:32:42.039455Z","shell.execute_reply.started":"2022-02-03T20:32:25.428429Z","shell.execute_reply":"2022-02-03T20:32:42.038668Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print(train)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T19:27:37.743758Z","iopub.execute_input":"2022-02-03T19:27:37.744496Z","iopub.status.idle":"2022-02-03T19:27:37.749825Z","shell.execute_reply.started":"2022-02-03T19:27:37.744456Z","shell.execute_reply":"2022-02-03T19:27:37.748806Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"print(test)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T19:27:43.211519Z","iopub.execute_input":"2022-02-03T19:27:43.212307Z","iopub.status.idle":"2022-02-03T19:27:43.219682Z","shell.execute_reply.started":"2022-02-03T19:27:43.212269Z","shell.execute_reply":"2022-02-03T19:27:43.217914Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"y_hat = knn.predict(test)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:23:30.109929Z","iopub.execute_input":"2022-02-03T20:23:30.110420Z","iopub.status.idle":"2022-02-03T20:23:32.548383Z","shell.execute_reply.started":"2022-02-03T20:23:30.110380Z","shell.execute_reply":"2022-02-03T20:23:32.547517Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"print(y_hat)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:23:34.750792Z","iopub.execute_input":"2022-02-03T20:23:34.752915Z","iopub.status.idle":"2022-02-03T20:23:34.758309Z","shell.execute_reply.started":"2022-02-03T20:23:34.752869Z","shell.execute_reply":"2022-02-03T20:23:34.757465Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"train_dir = '../input/blg453e-competition-2-2021/image-classification/imagenet_50/train'\n\ntrain_folders = sorted(os.listdir(train_dir))\nscore_of_img = [train_folders[int(y_hat_i)] for y_hat_i in y_hat]\n\nimport numpy as np\nnp.savetxt('output1.csv', [p for p in zip(test_labels, score_of_img)], delimiter=',', fmt='%s')","metadata":{"execution":{"iopub.status.busy":"2022-02-03T20:23:45.278825Z","iopub.execute_input":"2022-02-03T20:23:45.279539Z","iopub.status.idle":"2022-02-03T20:23:45.616452Z","shell.execute_reply.started":"2022-02-03T20:23:45.279495Z","shell.execute_reply":"2022-02-03T20:23:45.615670Z"},"trusted":true},"execution_count":41,"outputs":[]}]}