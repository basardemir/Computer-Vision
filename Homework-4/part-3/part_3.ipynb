{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Name: Başar Demir\n",
        "\n",
        "Student Number: 150180080"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wjYOxdBU9TH",
        "outputId": "0565910b-f125-441b-8705-9160a2dafa56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.10.0+cu111\n",
            "    Uninstalling torchaudio-0.10.0+cu111:\n",
            "      Successfully uninstalled torchaudio-0.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.10.2+cu113 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.10.2+cu113 torchaudio-0.10.2+cu113 torchvision-0.11.3+cu113\n"
          ]
        }
      ],
      "source": [
        "!pip install ninja\n",
        "!pip3 install torch==1.10.2+cu113 torchvision==0.11.3+cu113 torchaudio==0.10.2+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl27gdbJU_M5",
        "outputId": "ccfc9244-e6b1-4a11-f114-15c86a7b278d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rWehk_ETJ72F",
        "outputId": "037fee11-f45d-4a61-921c-e93d553cc4a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading pSp from checkpoint: /content/drive/MyDrive/PSPNet/pretrained_models/psp_ffhq_encode.pt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from argparse import Namespace\n",
        "import numpy as np\n",
        "import torch\n",
        "import sys\n",
        "import dlib\n",
        "\n",
        "sys.path.append(\".\")\n",
        "sys.path.append(\"..\")\n",
        "sys.path.append('/content/drive/MyDrive/PSPNet')\n",
        "\n",
        "from options.test_options import TestOptions\n",
        "from models.psp import pSp\n",
        "import cv2\n",
        "from scripts.align_all_parallel import align_face\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "#test_opts = TestOptions().parse()\n",
        "\n",
        "test_opts = Namespace(checkpoint_path=None, couple_outputs=False, data_path='gt_images', exp_dir=None, latent_mask=None, mix_alpha=None, n_images=None, n_outputs_to_generate=5, resize_factors=None, resize_outputs=False, test_batch_size=2, test_workers=2)\n",
        "\n",
        "\n",
        "test_opts.checkpoint_path = '/content/drive/MyDrive/PSPNet/pretrained_models/psp_ffhq_encode.pt'\n",
        "\n",
        "\n",
        "# update test options with options used during training\n",
        "ckpt = torch.load(test_opts.checkpoint_path, map_location='cpu')\n",
        "opts = ckpt['opts']\n",
        "opts.update(vars(test_opts))\n",
        "opts['output_size'] = 1024\n",
        "\n",
        "opts = Namespace(**opts)\n",
        "\n",
        "net = pSp(opts)\n",
        "net.eval()\n",
        "net.cuda()\n",
        "#Prepare the PSPNet + StyleGAN network\n",
        "\n",
        "transform = transforms.Compose([\n",
        "\ttransforms.Resize(size=(256, 256)),\n",
        "\ttransforms.ToTensor(),\n",
        "\ttransforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])]\n",
        ")\n",
        "#Preprocessing operations for each image\n",
        "\n",
        "predictor = dlib.shape_predictor(\"/content/drive/MyDrive/PSPNet/shape_predictor_68_face_landmarks.dat\")\n",
        "#Predict facial landmarks\n",
        "\n",
        "aligned_first_image = align_face(filepath=\"/content/drive/MyDrive/PSPNet/nuri.jpg\", predictor=predictor)\n",
        "aligned_first_image = aligned_first_image.convert(\"RGB\")\n",
        "\n",
        "aligned_second_image = align_face(filepath=\"/content/drive/MyDrive/PSPNet/face.jpg\", predictor=predictor)\n",
        "aligned_second_image = aligned_second_image.convert(\"RGB\")\n",
        "\n",
        "\n",
        "from_im = transform(aligned_first_image).unsqueeze(0)\n",
        "to_im = transform(aligned_second_image).unsqueeze(0)\n",
        "# Do preprocessing on the aligned face\n",
        "\n",
        "frames = []\n",
        "frame_count = 200\n",
        "\n",
        "with torch.no_grad():\n",
        "\tinput = from_im.float().cuda()\n",
        "\toutput = to_im.float().cuda()\n",
        "\n",
        "\t_, from_latent_vector = net(input, randomize_noise=False, resize=False, return_latents=True)\n",
        "\t_, to_latent_vector = net(output, randomize_noise=False, resize=False, return_latents=True)\n",
        "\t# Obtain features from input image\n",
        "\n",
        "\tfor i in range(frame_count+1):\n",
        "\t\tlatent_vector = ((from_latent_vector * (frame_count-i)) + (to_latent_vector*i))/frame_count\n",
        "\n",
        "\t\tresult, _ = net.decoder([latent_vector.float()],input_is_latent=True, randomize_noise=False, return_latents=False)\n",
        "\t\t# Feed features to the StyleGAN\n",
        "\n",
        "\t\tresult = result.squeeze().permute((1,2,0)).cpu().numpy()\n",
        "\n",
        "\t\tresult[result>1] = 1\n",
        "\t\tresult[result<-1] = -1\n",
        "\t\tresult = (255*(result+1)//2).astype(np.uint8)\n",
        "\t\n",
        "\t\tframes.append(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kU262VT9UqX",
        "outputId": "71354507-67de-4271-e932-8690cc96a233"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[MoviePy] >>>> Building video /content/drive/MyDrive/PSPNet/part-2.mp4\n",
            "[MoviePy] Writing video /content/drive/MyDrive/PSPNet/part-2.mp4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 202/202 [00:11<00:00, 18.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[MoviePy] Done.\n",
            "[MoviePy] >>>> Video ready: /content/drive/MyDrive/PSPNet/part-2.mp4 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "import moviepy.editor as mpy\n",
        "\n",
        "clip = mpy.ImageSequenceClip(frames , fps = 25)\n",
        "clip.write_videofile(\"/content/drive/MyDrive/PSPNet/part-3.mp4\", codec=\"libx264\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of inference.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
